ğŸ’³ AI-Assisted Billing System (Local Setup)

This project is a local, AI-assisted billing system that allows users to query and pay bills through a chat-based interface.

It demonstrates how a Large Language Model (LLM) can be integrated into a real backend system to understand user intent, route requests, and trigger real API calls â€” all running locally.

ğŸš€ What This Project Does

Users can interact with a billing system using natural language:

Ask for their bill

Request a detailed bill breakdown

See payment status

Pay bills using a Pay Now button

All interactions happen through a chat UI, backed by a real API, without exposing backend endpoints directly.

ğŸ§± System Architecture (Local)
[ React Chat UI ]
        â†“ (Firestore)
[ Python LLM Agent ]
        â†“ (HTTP)
[ Node.js Gateway ]
        â†“ (JWT)
[ ASP.NET Core Billing API ]
        â†“
[ Local Database ]

ğŸ§© Components
1ï¸âƒ£ Billing API (ASP.NET Core 8)

Core business logic

Bill management

Payment simulation

Role-based authorization

2ï¸âƒ£ Gateway Service (Node.js)

Acts as a secure proxy

Injects JWT tokens automatically

Separates client access from backend API

3ï¸âƒ£ LLM Agent (Python + Ollama)

Uses a local LLM (Ollama)

Extracts intent & slots from user messages

Produces strict JSON output

Decides which backend endpoint to call

4ï¸âƒ£ Chat UI (React + Firebase)

Real-time messaging with Firestore

Displays assistant responses

Shows Pay Now button only when allowed

No page refresh required

ğŸ¤– LLM Capabilities

The LLM is used only for intent understanding, not for business logic.

Supported intents:

query_bill

query_bill_detailed

pay_bill

help

Example user messages:

â€œShow my billâ€

â€œShow detailed billâ€

â€œIs my bill paid?â€

The LLM always returns valid JSON only, which is then validated and executed safely.

ğŸ” Authentication & Roles

JWT-based authentication with role separation:

Role	Description
Admin	Manages bills (API-level)
Mobile	Queries bills
Banking	Processes payments

Tokens are handled internally by the Gateway.

ğŸ“± Chat-Based Flow

User sends a message

Message is saved to Firestore

Python agent listens for new messages

LLM extracts intent and parameters

Agent calls Gateway

Gateway calls Billing API

Response is sent back to chat

UI updates in real time

ğŸ›  Technologies Used
Layer	Technology
Backend API	ASP.NET Core 8
ORM	Entity Framework Core
Database	Local SQL Database
Authentication	JWT Bearer Tokens
Gateway	Node.js (Express)
AI Agent	Python
LLM Runtime	Ollama
LLM Model	LLaMA 3.1
Frontend	React
Realtime DB	Firebase Firestore
API Docs	Swagger
ğŸ“¦ Project Structure
Billing.Api/
â”‚
â”œâ”€â”€ Controllers/
â”‚   â”œâ”€â”€ AuthController.cs
â”‚   â”œâ”€â”€ AdminController.cs
â”‚   â”œâ”€â”€ MobileController.cs
â”‚   â””â”€â”€ BankingController.cs
â”‚
â”œâ”€â”€ Data/
â”‚   â”œâ”€â”€ BillingDbContext.cs
â”‚   â””â”€â”€ SeedData.cs
â”‚
â”œâ”€â”€ Models/
â”œâ”€â”€ Dtos/
â”œâ”€â”€ Middleware/
â”‚
gateway-node/
agent-python/
frontend-react/

â–¶ï¸ Running the Project Locally
1ï¸âƒ£ Start Billing API
dotnet run

2ï¸âƒ£ Start Gateway
cd gateway-node
npm install
npm start

3ï¸âƒ£ Start LLM (Ollama)
ollama run llama3.1

4ï¸âƒ£ Start LLM Agent
cd agent-python
python main.py

5ï¸âƒ£ Start Frontend
cd frontend-react
npm install
npm start

ğŸ§ª Testing

Chat UI is the main interaction point

Swagger is available for backend inspection

All requests flow through the Gateway and Agent

ğŸ”’ Security Notes

No secrets are committed to GitHub

.env and service account files are ignored

All communication is local

ğŸ¥ Demo Video

The demo video shows:

Chat-based bill queries

LLM intent extraction

Bill detail vs summary

Payment flow with Pay Now button

(Source code is intentionally not shown in the video.)

âœ… Current Status

âœ” Fully local
âœ” Stable LLM integration
âœ” Chat-based UX complete
âœ” Ready for demo & submission

ğŸ“Œ Final Note

This project focuses on practical LLM usage, not just AI text generation â€” demonstrating how LLMs can safely drive real backend workflows.
